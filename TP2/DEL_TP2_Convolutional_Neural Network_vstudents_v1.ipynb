{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110b3ea8",
   "metadata": {},
   "source": [
    "<font  style=\"font-size: 3rem; color: darkviolet\"> Convolutional Neural Networks in TensorFlow's Keras API </font>\n",
    "\n",
    "AA - DEL - 2023/24 - TP2 - 3h\n",
    "\n",
    "Author: Francesca Galassi\n",
    "\n",
    "*This assignment is inspired by the Deep Learning course on Coursera by Andrew Ng, Stanford University, for which we are thankful.*\n",
    "\n",
    "**Submit this notebook with your solutions, answers and observations.**\n",
    "\n",
    "In this practical, you will learn how to build and train a Convolutional Neural Network (CNN) using TensorFlow's Keras Sequential API. The objective is to predict whether an individual's emotional state is positive or negative based on input image data. This task is important because only those who genuinely smile will be allowed into the Happy House.\n",
    "\n",
    "You can access the documentation for the Sequential API at the following link:\n",
    "https://www.tensorflow.org/guide/keras/sequential_model\n",
    "\n",
    "Reminder: \n",
    "\n",
    "- *Epoch*: One complete pass through the entire training dataset. During an epoch, the model learns from all training examples exactly once.\n",
    "\n",
    "- *Batch*: A subset of the training dataset processed in one forward pass and one backward pass. Weights are updated after processing each batch.\n",
    "\n",
    "- *Iterations*: The process of updating the weights based on the gradients computed from one batch of data. One iteration is completed when a batch of data has been processed.\n",
    "\n",
    "- *Training Steps*: The total number of steps to complete one epoch, equal to the total number of training examples divided by the batch size.\n",
    "\n",
    "- *Optimizer*: An algorithm used to minimize the loss function by updating the weights of the neural network during training. Common optimizers include Stochastic Gradient Descent (SGD), Adam, RMSprop, and Adagrad. Documentation: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [1 - The Happy House Dataset](#1)\n",
    "- [2 - The Sequential Model](#2)\n",
    "- [3 - Train and Evaluate the Model](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de70dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc9235a",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## <font color='darkviolet'> 1 - The Happy House dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49097e1",
   "metadata": {},
   "source": [
    "<a name='ex-1'></a>\n",
    "#### <font color='blue'> Exercise 1\n",
    "Exploring and describing the dataset is an essential initial step in any deep learning project. Follow the code and steps provided below to explore and describe the Happy House dataset. \n",
    "    \n",
    "(i.) Load the Happy House dataset, which contains images of people's faces labeled with whether they are smiling or not. To accomplish this, complete the implementation of the `load_happy_dataset` function. This function loads both the training and test datasets from HDF5 files and returns them as NumPy arrays. Additionally, it ensures that the input images are normalized by scaling pixel values to the range [0, 1], which can be achieved by dividing the pixel values by the maximum pixel value. Note that the labels are reshaped to have a shape of (m,1), where m represents the number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1efa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_happy_dataset():\n",
    "    \"\"\"\n",
    "    Load the Happy House dataset from HDF5 files.\n",
    "\n",
    "    Returns:\n",
    "    train_set_x -- numpy array containing features of the training set\n",
    "    train_set_y -- numpy array containing labels of the training set\n",
    "    test_set_x  -- numpy array containing features of the test set\n",
    "    test_set_y  -- numpy array containing labels of the test set\n",
    "    classes -- numpy array containing the list of classes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the training dataset\n",
    "    train_dataset = h5py.File('data/train_happy.h5', \"r\")\n",
    "    # Retrieve the keys within the HDF5 file\n",
    "    dataset_keys = list(train_dataset.keys())\n",
    "    print(dataset_keys[:])\n",
    "    \n",
    "    # Extract the features and labels for the training set\n",
    "    # Normalize pixel values\n",
    "    # TODO    \n",
    "    \n",
    "    # Load the test dataset\n",
    "    # TODO\n",
    "    \n",
    "    # Extract the features and labels for the test set\n",
    "    # Normalize pixel values\n",
    "    # TODO\n",
    "\n",
    "    # Extract the list of classes\n",
    "    # TODO\n",
    "\n",
    "    # Reshape the labels to match the expected shape\n",
    "    train_set_y = train_set_y.reshape((train_set_y.shape[0],1))\n",
    "    test_set_y = test_set_y.reshape((test_set_y.shape[0],1))\n",
    "    \n",
    "    return train_set_x, train_set_y, test_set_x, test_set_y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7242c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['list_classes', 'train_set_x', 'train_set_y']\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'train_set_y' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the Happy House dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train, Y_train, X_test, Y_test, classes \u001b[38;5;241m=\u001b[39m \u001b[43mload_happy_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m, in \u001b[0;36mload_happy_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_keys[:])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Extract the features and labels for the training set\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Normalize pixel values\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# TODO    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Reshape the labels to match the expected shape\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m train_set_y \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_set_y\u001b[49m\u001b[38;5;241m.\u001b[39mreshape((train_set_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     35\u001b[0m test_set_y \u001b[38;5;241m=\u001b[39m test_set_y\u001b[38;5;241m.\u001b[39mreshape((test_set_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_set_x, train_set_y, test_set_x, test_set_y, classes\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'train_set_y' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# Load the Happy House dataset\n",
    "X_train, Y_train, X_test, Y_test, classes = load_happy_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca59a4",
   "metadata": {},
   "source": [
    "(ii.) Describe the dataset by providing information about its size, dimensions of the images, labels, and the distribution of labels. Visualize a few images from the dataset along with their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa87ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e46a985",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## <font color='darkviolet'> 2 - The Sequential Model\n",
    "    \n",
    "The TensorFlow Keras Sequential API is an easy-to-use tool for building and training neural networks within the TensorFlow framework. It is suited for tasks that involve a sequential flow, where each layer takes one input and produces one output.\n",
    "\n",
    "To instantiate a Sequential model in Keras, a list of layers is provided to the Sequential constructor. These layers define the architecture of the neural network, and their sequence determines how data flows through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8837b35",
   "metadata": {},
   "source": [
    "<a name='ex-2'></a>\n",
    "#### <font color='blue'> Exercise 2\n",
    "\n",
    "(i.) Implement the `happyModel` function to create a CNN model with the following layers and configurations:\n",
    "    \n",
    "- ZeroPadding2D: Add padding of 3 pixels to the input shape.\n",
    "- Conv2D: Utilize 32 filters of size 7x7 with a stride of 1.\n",
    "- BatchNormalization: Normalize the input along the depth axis (channels or feature maps).\n",
    "- ReLU: Apply Rectified Linear Unit activation.\n",
    "- MaxPool2D: Perform max pooling using default parameters.\n",
    "- Flatten: Flatten the output of the previous layer.\n",
    "- Fully-connected (Dense) layer: Add a fully connected layer with 1 unit and apply a sigmoid activation.\n",
    "\n",
    "Documentation: https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "    \n",
    "Note: In Batch Normalization, input values are normalized using their mean and variance over a mini-batch, ensuring a mean of zero and standard deviation of one to stabilize learning. Next, learnable parameters, gamma and beta, adjust normalized values, aiding in capturing complex patterns and accelerating learning. During testing, estimated statistics from training are used to maintain consistency between training and inference phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1344404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def happyModel(input_shape=(64, 64, 3)):\n",
    "    \"\"\"\n",
    "    Implementation of the HappyModel.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the model architecture\n",
    "    # TODO\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef3cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing the implementation\n",
    "from termcolor import colored\n",
    "\n",
    "def comparator(learner, instructor):\n",
    "    for a, b in zip(learner, instructor):\n",
    "        if a != b:\n",
    "            print(colored(\"Test failed\", attrs=['bold']),\n",
    "                  \"\\n Expected value \\n\\n\", colored(f\"{b}\", \"green\"), \n",
    "                  \"\\n\\n does not match the input value: \\n\\n\", \n",
    "                  colored(f\"{a}\", \"red\"))\n",
    "            raise AssertionError(\"Error in test\") \n",
    "    print(colored(\"All tests passed!\", \"green\"))\n",
    "\n",
    "def summary(model):\n",
    "    result = []\n",
    "    for layer in model.layers:\n",
    "        descriptors = [layer.__class__.__name__, layer.output_shape, layer.count_params()]\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            descriptors.extend([layer.padding, layer.activation.__name__, layer.kernel_initializer.__class__.__name__])\n",
    "        elif isinstance(layer, tf.keras.layers.MaxPooling2D):\n",
    "            descriptors.extend([layer.pool_size, layer.strides, layer.padding])\n",
    "        elif isinstance(layer, tf.keras.layers.Dropout):\n",
    "            descriptors.append(layer.rate)\n",
    "        elif isinstance(layer, tf.keras.layers.ZeroPadding2D):\n",
    "            descriptors.append(layer.padding)\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            descriptors.append(layer.activation.__name__)\n",
    "        result.append(descriptors)\n",
    "    return result\n",
    "\n",
    "\n",
    "happy_model = happyModel()\n",
    "\n",
    "# Get the summary of the model\n",
    "model_summary = summary(happy_model)\n",
    "\n",
    "# The expected layer configurations\n",
    "output = [\n",
    "    ['ZeroPadding2D', (None, 70, 70, 3), 0, ((3, 3), (3, 3))],\n",
    "    ['Conv2D', (None, 64, 64, 32), 4736, 'valid', 'linear', 'GlorotUniform'],\n",
    "    ['BatchNormalization', (None, 64, 64, 32), 128],\n",
    "    ['ReLU', (None, 64, 64, 32), 0],\n",
    "    ['MaxPooling2D', (None, 32, 32, 32), 0, (2, 2), (2, 2), 'valid'],\n",
    "    ['Flatten', (None, 32768), 0],\n",
    "    ['Dense', (None, 1), 32769, 'sigmoid']\n",
    "]\n",
    "\n",
    "# Compare the two inputs\n",
    "comparator(model_summary, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ec626",
   "metadata": {},
   "source": [
    "(ii.) After constructing a model, the next step is to compile it for training. This involves specifying settings such as the optimizer, loss function, and performance metrics.\n",
    "\n",
    "To compile the model, utilize the `.compile()` method and set the following configurations:\n",
    "\n",
    "- Optimizer: Use the Adam optimizer with an initial learning rate of 0.0001. Note: Adam optimizer dynamically adjusts the learning rate for each parameter during training based on their past gradients and second moments.\n",
    "\n",
    "- Loss Function: Specify `binary_crossentropy` as the loss function since the task involves binary classification, determining if someone is smiling or not.\n",
    "\n",
    "- Metrics: Track the `accuracy` metric throughout the training process to assess the model's performance.\n",
    "\n",
    "For further information on various optimizers, refer to the TensorFlow documentation: \n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4875e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c164ebc",
   "metadata": {},
   "source": [
    "(iii.) Invoke the `.summary()` method on `happy_model` to display a summary of the model architecture and its parameters. Answer the following questions:\n",
    "\n",
    "**Q1** What is the distinction between trainable and non-trainable parameters?\n",
    "    \n",
    "\n",
    "**Q2** For each layer in the model architecture, outline the steps to calculate the total number of trainable parameters. Additionally, identify the source of the 64 non-trainable parameters.\n",
    "    \n",
    "\n",
    "**Q3** In the output dimensions of a layer, the first dimension is labeled as `None`. Can you explain what this signifies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8510f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d177b",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## <font color='darkviolet'> 3 - Training and Evaluating the Model\n",
    "    \n",
    "<a name='ex-3'></a>\n",
    "#### <font color='blue'> Exercise 3\n",
    "\n",
    "(i.) After creating and compiling the model, the next step is to train it on the labeled dataset. This is done by calling the `.fit()` method, which automates various aspects of training, including backpropagation. When calling `.fit()`, you'll need to specify several parameters to configure the training process:     \n",
    "- *Number of Epochs*: how many times the model will iterate over the entire dataset during training. Each iteration comprises a forward pass (predicting outputs) and a backward pass (updating model parameters based on computed errors).\n",
    "- *Batch Size*: the number of samples processed before the model's parameters are updated. \n",
    "- *Validation Split*: the portion of training data for validation. During training, the model's performance on this validation subset is monitored to evaluate its generalization ability.\n",
    "\n",
    "To automatically save the best model during training, you can use the `ModelCheckpoint` callback with `.fit()`. You can find more details in the documentation https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback. Additionally, to prevent overfitting, you can combine `EarlyStopping` with `ModelCheckpoint`. `EarlyStopping` monitors a specific metric and stops training when this metric no longer improves for a certain number of epochs. By combining it with `ModelCheckpoint`, you can save the best model while avoiding overfitting.\n",
    "    \n",
    "Your task is to implement the use of `ModelCheckpoint` and `EarlyStopping` callbacks during model training. While your model is learning, keep track of the loss and accuracy metrics for both the training and validation datasets. Monitor the progress of each epoch. \n",
    "    \n",
    "Note: The `.fit()` method returns a History object, containing information about the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746de249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999dec27",
   "metadata": {},
   "source": [
    "(ii.) Observe the training process, including the changes in loss and accuracy over each epoch, for the training and validation test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91d46b",
   "metadata": {},
   "source": [
    "(iii.) After training the model, evaluate its performance on unseen data to understand how well it generalizes beyond the training set. By using the `.evaluate()` method, you can quantify how effectively your model performs on new, previously unseen data from the test set. Describe your results. Modify the architecture and or the hyperparameters and observe the change in performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf0327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ff68c",
   "metadata": {},
   "source": [
    " (iv.) Bonus: Explore how changes in architecture or hyperparameters affect your model's performance. Experiment with changes such as adding/removing layers or altering their configurations. Retrain the model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f308e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
